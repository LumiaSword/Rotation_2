---
title: "R Notebook"
output: html_notebook
---


# Notes

The second rotation is centered around the downstream data analysis of ribo-seq. Ribosomal analysis was performed by sequencing the Ribosome Protected Footprints (RPFs), which reflects the status of the ribosome through the mRNA fragments undergoing translation, thus obtaining a distribution of reads of a specific length at the transcript level. Data were analyzed using the RiboR software package.

## Updates
1. Review ribosome-profiling. Learn how to use RiboR. Go through tutorial.

2. Use real .ribo data. Filter for the top 100 transcripts with the highest read counts. Check their coverage in each CDS regions. Visualize the distribution.

3. Adjust the way bins are divided.

    before: Position/transcript cds region length to get a relative length. Relative length * 100 and downward rounding to get position assigned to each bin. 
    
    after: A determined number of bins are set. Transcripts with different region lengths have different position ranges in the each bin.
4. For each bins, the distribution of all transcripts is represented by adding up ~~raw counts~~ their respective densities;

    The distribution map is extended to the full transcript range.

    Decide how to set different numbers of bins for different regions.

    Rearrange the order of heatmaprows. Cluster between transcripts.

    Observe outliers transcripts. Try to explain.

5. Backed up using git; add comments; for WDR74 and MTRNR2L, documented and excluded from subsequent analyses

    The correctness of the method was verified using a test set.

    Try to demonstrate the read distribution for higher precision regions.

    If the method is correct, try to explain the high enrichment of readings in the UTR region.

    After confirming the flow of the method, apply it to all 6 experiments.

    Observe if there is a consistent trend in the expression of transcripts across the six experiments?

    How can we programmatically identify differences in trends?
    
    For NPMI-201 and PPIA-204, why they are partially not expressed in the CDS region?

# Packages

```{r}
library(ribor) # To process the 
library(tidyverse)
library(ggplot2)
library(viridis)
library(pheatmap)
library(grid)
```

# Data sources

Open source data from [NCBI](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE158374). .ribo file are generated using [riboflow](https://github.com/ribosomeprofiling/riboflow).

```{r}
h1299.ribo = Ribo("GSE158374_H1299.ribo.hdf5", rename = rename_default )
hek293.ribo = Ribo("GSE158374_manuscript.HEK293.ribo.hdf5",rename = rename_default )
```

# H1299

\
```{r}
h1299.ribo

# coverage T, rna T
```


```{r}
h1299.start = get_metagene(ribo.object = h1299.ribo, 
                           site        = "start",
                           range.lower = 28,
                           range.upper = 32,
                           length      = FALSE,
                           transcript  = FALSE,
                           alias       = TRUE)

h1299.start[1:5,c(1,2,3,53,54,55)]
```

```{r}
head(get_reference_names(h1299.ribo), 2)
```


```{r}
plot_region_counts(x           = h1299.ribo,
                   range.lower = 28,
                   range.upper = 32)
```



```{r}
h1299.rc = get_region_counts(h1299.ribo,
                        range.lower = 28,
                        range.upper = 32,
                        length      = T,
                        transcript  = F,
                        alias = T,
                        compact = F)
```


```{r}
top100_h1299_cds = h1299.rc %>%
  filter(region == "CDS") %>%
  group_by(transcript) %>%
  summarise(total_count = sum(count)) %>%
  arrange(desc(total_count))%>%
  head(100) %>%
  pull(transcript)
```


```{r}
top100_h1299 = h1299.rc %>%
  group_by(transcript) %>%
  summarise(total_count = sum(count)) %>%
  arrange(desc(total_count)) %>%
  head(100) %>%
  pull(transcript)
```

```{r}
rc_top100 = get_region_counts(h1299.ribo,
                        range.lower = 28,
                        range.upper = 32,
                        length      = T,
                        transcript  = F,
                        alias = T,
                        compact = F,
                  tidy = F) %>%
  filter(transcript %in% top100_h1299)

rc_top100
```


```{r}
region_coord = get_original_region_coordinates(ribo.object = h1299.ribo , alias = TRUE)

top100_region_coord = region_coord %>%
    filter(transcript %in% top100_h1299) 

top100_cds_region_coord = region_coord %>%
    filter(transcript %in% top100_h1299_cds) 
```


```{r}
top100_region_coord %>%
  group_by(transcript) %>%
  summarise(UTR5 = UTR5_stop - UTR5_start,CDS = CDS_stop - CDS_start, UTR3 = UTR3_stop - UTR3_start) %>%
  ungroup() 
```



```{r}
experiment.info = get_info(ribo.object = h1299.ribo)[['experiment.info']]
has.coverage = experiment.info[experiment.info$coverage == TRUE, "experiment"]
exp.names <- has.coverage[1] # 1-A
```

```{r}
top100_region_coord %>%
    filter(transcript == top100_h1299[i]) %>%
    pull(CDS_start)
```




```{r}
cov_list = list()

n_bins_utr5 = 30
n_bins_cds = 100
n_bins_utr3 = 30

# experiment: 20210318-NSP1-H1299-A
for (i in 1:length(top100_h1299)) {
  # cds region bond
  cds_start = top100_region_coord %>%
    filter(transcript == top100_h1299[i]) %>%
    pull(CDS_start)
  
  cds_end = top100_region_coord %>%
    filter(transcript == top100_h1299[i]) %>%
    pull(CDS_stop)
  
  # utr5 region bond
  utr5_start = 1
  utr5_end = cds_start - 1
  
  # utr3 region bond
  utr3_start = cds_end + 1
  utr3_end = top100_region_coord %>%
    filter(transcript == top100_h1299[i]) %>%
    pull(UTR3_stop)
  
  utr5_length = utr5_end - utr5_start + 1
  cds_length = cds_end - cds_start + 1
  utr3_length = utr3_end - utr3_start + 1
  
  bin_size_utr5 = utr5_length / n_bins_utr5
  bin_size_cds = cds_length / n_bins_cds
  bin_size_utr3 = utr3_length / n_bins_utr3
  
  cov_df = get_coverage(ribo.object = h1299.ribo,
                    name        = top100_h1299[i],
                    range.lower = 28,
                    range.upper = 32,
                    length      = T,
                    alias       = TRUE,
                    tidy        = TRUE,
                    compact     = F,
                    experiment  = exp.names)
  
  cov_df = cov_df %>%
    mutate(position = as.numeric(position)) %>%
    mutate(region = case_when(
      position >= utr5_start & position <= utr5_end ~ "UTR5",
      position >= cds_start & position <= cds_end ~ "CDS",
      position >= utr3_start & position <= utr3_end ~ "UTR3",
      TRUE ~ NA_character_
    )) %>%
    filter(!is.na(region)) %>%
    mutate(relative_position = case_when(
      region == "UTR5" ~ (position - utr5_start + 1),
      region == "CDS" ~ (position - cds_start + 1),
      region == "UTR3" ~ (position - utr3_start + 1)
    )) %>%
    mutate(bin = case_when(
      region == "UTR5" ~ ceiling(relative_position / bin_size_utr5),
      region == "CDS" ~ ceiling(relative_position / bin_size_cds),
      region == "UTR3" ~ ceiling(relative_position / bin_size_utr3)
    ))
  
  cov_df$bin[cov_df$region == "UTR5" & cov_df$bin > n_bins_utr5] = n_bins_utr5
  cov_df$bin[cov_df$region == "CDS" & cov_df$bin > n_bins_cds] = n_bins_cds
  cov_df$bin[cov_df$region == "UTR3" & cov_df$bin > n_bins_utr3] = n_bins_utr3
  
  all_cov = cov_df %>%
    group_by(region, bin) %>%
    summarise(total_count = sum(count),.groups = "drop") %>%
    mutate(transcript = top100_h1299[i]) 
    
  
  cov_list[[top100_h1299[i]]] = all_cov
  
}


coverage_all = bind_rows(cov_list)
```




```{r}
top100_h1299[i]
utr5_start
utr5_end
utr5_length

cds_start
cds_end
cds_length

utr3_start
utr3_end
utr3_length
```

```{r}
coverage_all 
```


```{r}
coverage_all = coverage_all %>%
  mutate(region = factor(region, levels = c("UTR5", "CDS", "UTR3")))
```


```{r}
coverage_all %>%
  group_by(transcript,region) %>%
  mutate(density = total_count / sum(total_count))  %>% # density will turn NA if total_count in certain region to be 0
  ungroup() %>%
  group_by(region,bin) %>%
  summarise(count = sum(density,na.rm = T),.groups = "drop") %>%
  ggplot(aes(x = bin, y = count)) +
  geom_line() +
  labs(
    x = "Bin",
    y = "Sum Read Count Density"
  ) +
  facet_wrap(~ region, scales = "free_x")

coverage_all %>%
  group_by(region,bin) %>%
  summarise(count = sum(total_count),.groups = "drop") %>%
  ggplot(aes(x = bin, y = count)) +
  geom_line() +
  labs(
    x = "Bin",
    y = "Sum Read Count"
  ) +
  facet_wrap(~ region, scales = "free_x")
```

> Would it be a good idea to use density to represent the reads number in each bin of each transcript in a heatmap?


```{r}
coverage_heatmap = coverage_all %>%
  mutate(transcript = factor(transcript, levels = rev(top100_h1299)))

coverage_heatmap %>%
  ggplot(aes(x = bin, y = transcript, fill = log10(total_count+1)))+
  geom_tile() +
  labs(
    x = "Bin",
    y = "Transcript",
    fill = "Read Count")+
  scale_fill_viridis_c()  + 
  facet_grid(~ region, scales = "free_x", space = "free")
```



```{r}
coverage_wide = coverage_all %>%
  group_by(transcript) %>%
  arrange(region)  %>%
  mutate(transcript = factor(transcript, levels = top100_h1299)) %>%
  arrange(transcript) %>%
  pivot_wider(names_from = c(region, bin), values_from = total_count)

dist_matrix = dist(coverage_wide[,-1])
hc = hclust(dist_matrix, method = "ward.D2")
order = coverage_wide$transcript[hc$order]
```

```{r}
coverage_matrix_data = as.matrix(coverage_wide[,-1])  # rm transcript col
rownames(coverage_matrix_data) = coverage_wide$transcript  

annotation_col = data.frame(
  Region = ifelse(grepl("UTR5", colnames(coverage_matrix_data)), "UTR5",
                  ifelse(grepl("CDS", colnames(coverage_matrix_data)), "CDS", "UTR3"))
)
rownames(annotation_col) <- colnames(coverage_matrix_data)
```


```{r}
pheatmap(
  log10(coverage_matrix_data + 1),
  cluster_rows = TRUE,  # cluster based on rows
  cluster_cols = F,  
  show_rownames = TRUE,  # show the transcripts' name
  show_colnames = F,  
  color = viridis(50),  
  annotation_col = annotation_col,
  main = "Transcripts Read Count Heatmap"
)

```

```{r}
# test to see if changes will be posted on the github
```

